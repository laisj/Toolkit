{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.sess = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.layer_keeps = None\n",
    "        self.vars = None\n",
    "        self.keep_prob_train = None\n",
    "        self.keep_prob_test = None\n",
    "\n",
    "    def run(self, fetches, X=None, y=None, mode='train'):\n",
    "            feed_dict = {}\n",
    "            if type(self.X) is list:\n",
    "                for i in range(len(X)):\n",
    "                    feed_dict[self.X[i]] = X[i]\n",
    "            else:\n",
    "                feed_dict[self.X] = X\n",
    "            if y is not None:\n",
    "                feed_dict[self.y] = y\n",
    "            if self.layer_keeps is not None:\n",
    "                if mode == 'train':\n",
    "                    feed_dict[self.layer_keeps] = self.keep_prob_train\n",
    "                elif mode == 'test':\n",
    "                    feed_dict[self.layer_keeps] = self.keep_prob_test\n",
    "            return self.sess.run(fetches, feed_dict)\n",
    "\n",
    "    def dump(self, model_path):\n",
    "        var_map = {}\n",
    "        for name, var in self.vars.iteritems():\n",
    "            var_map[name] = self.run(var)\n",
    "        pkl.dump(var_map, open(model_path, 'wb'))\n",
    "        print('model dumped at', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(Model):\n",
    "    def __init__(self, field_sizes=None, num_statistic_dim=0, embed_size=10, layer_sizes=None, layer_acts=None, drop_out=None,\n",
    "                 embed_l2=None, layer_l2=None, init_path=None, opt_algo='gd', learning_rate=1e-2, random_seed=None):\n",
    "        Model.__init__(self)\n",
    "        init_vars = []\n",
    "        # 这里是域的个数，也就是54个\n",
    "        num_inputs = len(field_sizes)\n",
    "        # xavier是个矩阵，长是域中可能值的个数，比如说custommomoid就是几千个广告主，宽是隐向量的维度，这里是10，所以是54个矩阵\n",
    "        # 占了 54 * 30000 * 10的内存\n",
    "        for i in range(num_inputs):\n",
    "            init_vars.append(('embed_%d' % i, [field_sizes[i], embed_size], 'xavier', dtype))\n",
    "        node_in = num_inputs * embed_size\n",
    "        for i in range(len(layer_sizes)):\n",
    "            # layer size目前是3层，每层加偏置项，1000那一层，w就是embeding后的个数*1000，下一层是1000*100\n",
    "            init_vars.append(('w%d' % i, [node_in, layer_sizes[i]], 'xavier', dtype))\n",
    "            # 每一个节点都有偏置项，其实可以化简为只有一个\n",
    "            init_vars.append(('b%d' % i, [layer_sizes[i]], 'zero', dtype))\n",
    "            node_in = layer_sizes[i]\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            if random_seed is not None:\n",
    "                tf.set_random_seed(random_seed)\n",
    "            self.X = [tf.sparse_placeholder(dtype) for i in range(num_inputs)]\n",
    "            self.y = tf.placeholder(dtype)\n",
    "            self.keep_prob_train = 1 - np.array(drop_out)\n",
    "            self.keep_prob_test = np.ones_like(drop_out)\n",
    "            self.layer_keeps = tf.placeholder(dtype)\n",
    "            self.vars = utils.init_var_map(init_vars, init_path)\n",
    "            w0 = [self.vars['embed_%d' % i] for i in range(num_inputs)]\n",
    "            # 这一句进行embeding，每一个域中有一个不是一的值，刮取出隐向量，最后concat之后就是54*10=540维，这时已经不是0和1\n",
    "            # ftrl与adagrad主要是在这一层网络要用，因为各种id的频率很不一致\n",
    "            # 如果要把离散值加入，就要变成xw.extend(数值型特征)\n",
    "            xw = tf.concat([tf.sparse_tensor_dense_matmul(self.X[i], w0[i]) for i in range(num_inputs)], 1)\n",
    "            # x:[[0,1,0],[1,0,0],1.2,1.3,0.9]\n",
    "            xw2 = tf.concat([xw, [self.X[i] for i in range(num_inputs, num_inputs + num_statistic_dim)]], 1)\n",
    "            l = xw2\n",
    "\n",
    "            for i in range(len(layer_sizes)):\n",
    "                wi = self.vars['w%d' % i]\n",
    "                bi = self.vars['b%d' % i]\n",
    "                print(l.shape, wi.shape, bi.shape)\n",
    "                l = tf.nn.dropout(\n",
    "                    utils.activate(\n",
    "                        tf.matmul(l, wi) + bi,\n",
    "                        layer_acts[i]),\n",
    "                    self.layer_keeps[i])\n",
    "\n",
    "            l = tf.squeeze(l)\n",
    "            self.y_prob = tf.sigmoid(l)\n",
    "\n",
    "            self.loss = tf.reduce_mean(\n",
    "                tf.nn.sigmoid_cross_entropy_with_logits(logits=l, labels=self.y))\n",
    "            if layer_l2 is not None:\n",
    "                self.loss += embed_l2 * tf.nn.l2_loss(xw)\n",
    "                for i in range(len(layer_sizes)):\n",
    "                    wi = self.vars['w%d' % i]\n",
    "                    self.loss += layer_l2[i] * tf.nn.l2_loss(wi)\n",
    "            self.optimizer = utils.get_optimizer(opt_algo, learning_rate, self.loss)\n",
    "\n",
    "            config = tf.ConfigProto()\n",
    "            config.gpu_options.allow_growth = True\n",
    "            self.sess = tf.Session(config=config)\n",
    "            tf.global_variables_initializer().run(session=self.sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x11077d4d0>,\n",
       " <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x110937c50>,\n",
       " <tf.Tensor 'Placeholder_179:0' shape=(1,) dtype=float32>]"
      ]
     },
     "execution_count": 25,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "num_inputs = 2\n",
    "X = [tf.sparse_placeholder(tf.float32) for i in range(num_inputs)]\n",
    "X.append(tf.placeholder(tf.float32,[1]))\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tried to convert 'input' to a tensor and failed. Error: None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5033578e374c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mw0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw01\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m xw = tf.concat([tf.sparse_tensor_dense_matmul(X[i], w0[i]) \n\u001b[0;32m----> 9\u001b[0;31m                 for i in range(num_inputs)].append([X[2]]), 1)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#xw = tf.concat(wx, X[2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1096\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m               tensor_shape.scalar())\n\u001b[0;32m-> 1098\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \"\"\"\n\u001b[1;32m    124\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.pyc\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   2069\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2070\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 2071\u001b[0;31m         \"Identity\", input=input, name=name)\n\u001b[0m\u001b[1;32m   2072\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2073\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    526\u001b[0m               raise ValueError(\n\u001b[1;32m    527\u001b[0m                   \u001b[0;34m\"Tried to convert '%s' to a tensor and failed. Error: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                   (input_name, err))\n\u001b[0m\u001b[1;32m    529\u001b[0m             prefix = (\"Input '%s' of '%s' Op has type %s that does not match\" %\n\u001b[1;32m    530\u001b[0m                       (input_name, op_type_name, observed))\n",
      "\u001b[0;31mValueError\u001b[0m: Tried to convert 'input' to a tensor and failed. Error: None values not supported."
     ]
    }
   ],
   "source": [
    "w00 = tf.Variable(tf.random_uniform([3000, 10], minval=-1e-3, maxval=1e-3, dtype=tf.float32),\n",
    "                                            name='xavier', dtype=tf.float32)\n",
    "w01 = tf.Variable(tf.random_uniform([3000, 10], minval=-1e-3, maxval=1e-3, dtype=tf.float32),\n",
    "                                            name='xavier', dtype=tf.float32)\n",
    "\n",
    "w0 = [w00, w01]\n",
    "xw = tf.concat([tf.sparse_tensor_dense_matmul(X[i], w0[i]) \n",
    "                for i in range(num_inputs)].append([X[2]]), 1)\n",
    "#xw = tf.concat(wx, X[2])\n",
    "\n",
    "#xw2 = tf.concat([X,X,X], 1)\n",
    "\n",
    "\n",
    "\n",
    "xw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reshape([0,0],shape=[-1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}